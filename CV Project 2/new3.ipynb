{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "import os\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_left_path = 'data/train/left'\n",
    "train_right_path = 'data/train/right'\n",
    "test_left_path = 'data/test/left'\n",
    "test_right_path = 'data/test/right'\n",
    "test_candidates = 'data/test_candidates.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 2000/2000 [02:22<00:00, 14.01it/s]\n",
      "Extracting Features: 100%|██████████| 2000/2000 [02:23<00:00, 13.99it/s]\n",
      "Extracting Features: 100%|██████████| 2000/2000 [02:29<00:00, 13.40it/s]\n",
      "Extracting Features: 100%|██████████| 2000/2000 [02:31<00:00, 13.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. 定义图像预处理流程\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 加载预训练的DenseNet121模型并移除全连接层\n",
    "densenet_model = models.densenet121(pretrained=True).features\n",
    "densenet_model = densenet_model.to(device).eval()\n",
    "\n",
    "# 3. 定义从图像中提取特征的函数\n",
    "# 3. 定义从图像中提取特征的函数\n",
    "def extract_features_densenet(image_path, model):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_features_to_hdf5(image_folder, model, output_hdf5_path):\n",
    "    image_list = [os.path.splitext(f)[0] for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "    with h5py.File(output_hdf5_path, 'w') as f:\n",
    "        for img_name in tqdm(image_list, desc=\"Extracting Features\"):\n",
    "            img_path = os.path.join(image_folder, f\"{img_name}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                features = extract_features_densenet(img_path, model)\n",
    "                f.create_dataset(img_name, data=features)\n",
    "            else:\n",
    "                print(f\"Warning: Image not found at path: {img_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 保存特征到 HDF5\n",
    "save_features_to_hdf5(train_left_path, densenet_model, 'data/train_left_features_densenet.hdf5')\n",
    "save_features_to_hdf5(train_right_path, densenet_model, 'data/train_right_features_densenet.hdf5')\n",
    "save_features_to_hdf5(test_left_path, densenet_model, 'data/test_left_features_densenet.hdf5')\n",
    "save_features_to_hdf5(test_right_path, densenet_model, 'data/test_right_features_densenet.hdf5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "def load_features_from_hdf5(hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        data = {}\n",
    "        for key in keys:\n",
    "            # 将数据平坦化并转换为一个一维数组\n",
    "            flattened_data = f[key][()].flatten()\n",
    "            data[key] = flattened_data\n",
    "        # 从平坦数据创建DataFrame\n",
    "        df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    return df\n",
    "\n",
    "# 示例：从 HDF5 加载特征到 pandas DataFrame\n",
    "train_left_features_df = load_features_from_hdf5('data/train_left_features_densenet.hdf5')\n",
    "train_right_features_df = load_features_from_hdf5('data/train_right_features_densenet.hdf5')\n",
    "\n",
    "# 现在 train_left_features_df 和 train_right_features_df 是包含特征的 pandas DataFrames，索引是图片的名字\n",
    "test_left_features_df = load_features_from_hdf5('data/test_left_features_densenet.hdf5')\n",
    "test_right_features_df = load_features_from_hdf5('data/test_right_features_densenet.hdf5')\n",
    "\n",
    "train_pairs = pd.read_csv('data/train.csv', header=None, names=['left', 'right'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 512)\n",
    "        \n",
    "    def forward_one(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 对比损失\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
    "        losses = 0.5 * (target.float() * distances +\n",
    "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SiameseNetwork(input_dim=train_left_features_df.shape[1]).to(device)\n",
    "criterion = ContrastiveLoss(margin=1.0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(df_features, model, device):\n",
    "    embeddings = []\n",
    "    image_to_index = {}\n",
    "    for index, (image_name, features) in enumerate(df_features.iterrows()):\n",
    "        tensor_features = torch.tensor(features.values, dtype=torch.float).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.forward_one(tensor_features)\n",
    "        embeddings.append(embedding.cpu().numpy().flatten())\n",
    "        image_to_index[image_name] = index\n",
    "    return np.array(embeddings), image_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, features_df):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    embeddings = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_id, features in features_df.iterrows():\n",
    "            features_tensor = torch.tensor(features.values).float().to(device)\n",
    "            embedding = model.forward_one(features_tensor.unsqueeze(0))\n",
    "            embeddings[img_id] = embedding.cpu().numpy().flatten()\n",
    "            \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_left, _ = extract_embeddings(train_left_features_df, model, device)\n",
    "train_embeddings_right, image_to_index = extract_embeddings(train_right_features_df, model, device)\n",
    "test_left_embeddings, _ = extract_embeddings(test_left_features_df, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 检查不一致的图像名\n",
    "print(set(test_left_features_df.index) - set(image_to_index.keys()))\n",
    "print(set(image_to_index.keys()) - set(test_left_features_df.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SUYUZH~1\\AppData\\Local\\Temp/ipykernel_38212/1391394337.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mtest_candidate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/test_candidates.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# 计算相似度得分\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0msimilarity_scores_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_test_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_left_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_candidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 保存到CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SUYUZH~1\\AppData\\Local\\Temp/ipykernel_38212/1391394337.py\u001b[0m in \u001b[0;36mcompare_test_embeddings\u001b[1;34m(test_embeddings, train_embeddings, test_candidate_df, image_to_index)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_candidate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0memb_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mscores_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'abm'"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def generate_embeddings(model, features_df):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    embeddings = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_id, features in features_df.iterrows():\n",
    "            features_tensor = torch.tensor(features.values).float().to(device)\n",
    "            embedding = model.forward_one(features_tensor.unsqueeze(0))\n",
    "            embeddings[img_id] = embedding.cpu().numpy().flatten()\n",
    "            \n",
    "    return embeddings\n",
    "\n",
    "# 4. 生成测试集嵌入\n",
    "test_left_embeddings = generate_embeddings(model, test_left_features_df)\n",
    "\n",
    "# 5. 比较嵌入，生成测试集相似度得分\n",
    "def compare_test_embeddings(test_embeddings, train_embeddings, test_candidate_df, image_to_index):\n",
    "    scores = []\n",
    "    \n",
    "    for idx, (left_img, *candidates) in test_candidate_df.iterrows():\n",
    "       \n",
    "        emb_left = test_embeddings[image_to_index[left_img]]\n",
    "\n",
    "        scores_row = [left_img]\n",
    "        for right_img in candidates:\n",
    "            emb_index = image_to_index[right_img]\n",
    "            emb_right = train_embeddings[emb_index]\n",
    "            score = 1 - cosine(emb_left, emb_right)\n",
    "            scores_row.append(score)\n",
    "        scores.append(scores_row)\n",
    "\n",
    "        print(test_left_features_df.head())\n",
    "        print('abm' in test_left_features_df.index)\n",
    "\n",
    "    return pd.DataFrame(scores, columns=test_candidate_df.columns)\n",
    "\n",
    "\n",
    "test_candidate = pd.read_csv('data/test_candidates.csv')\n",
    "# 计算相似度得分\n",
    "similarity_scores_df = compare_test_embeddings(test_left_embeddings, train_embeddings_right, test_candidate, image_to_index)\n",
    "\n",
    "# 保存到CSV\n",
    "similarity_scores_df.to_csv('similarity_scores.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
